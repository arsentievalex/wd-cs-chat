llm:
  provider: openai
  config:
    model: 'gpt-3.5-turbo-0125'
    temperature: 0.0
    stream: true